{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Method Selection\n",
    "This Python code imports several libraries used for data analysis, machine learning, and data visualization (like sklearn, pandas, numpy, etc). It also modifies the system path to include the parent directory, which allows for the import of custom modules located elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# https://scikit-learn.org/stable/index.html\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/index.html\n",
    "# - https://scikit-learn.org/stable/auto_examples/linear_model/index.html\n",
    "\n",
    "# https://scikit-learn.org/stable/tutorial/index.html\n",
    "# - https://scikit-learn.org/stable/tutorial/statistical_inference/index. html\n",
    "\n",
    "# https://scikit-learn.org/stable/user_guide.html\n",
    "# - https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/classes.html#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictor.broker.ETTAgent"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import predictor.broker as broker\n",
    "broker.ETTAgent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  imports necessary modules, reads two CSV files (rotterdam_hamburg.csv & felixstowe_rotterdam.csv)into pandas DataFrames, applies a cleaning function from the predictor.clean module to each DataFrame, and then concatenates the two cleaned DataFrames into one combined DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artur\\AppData\\Local\\Temp\\ipykernel_8260\\2428302333.py:8: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_rtm_ham_raw = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rtm_ham: (500142, 25) to (351170, 25) (148972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artur\\AppData\\Local\\Temp\\ipykernel_8260\\2428302333.py:15: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fxt_rtm_raw = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_fxt_rtm: (527359, 26) to (239546, 25) (287813)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import predictor.clean as clean\n",
    "\n",
    "\n",
    "df_rtm_ham_raw = pd.read_csv(\n",
    "    '../resources/rotterdam_hamburg/rotterdam_hamburg.csv', quotechar=\"'\")\n",
    "df_rtm_ham = clean.clean_up(df_rtm_ham_raw)\n",
    "print(\n",
    "    f\"df_rtm_ham: {df_rtm_ham_raw.shape} to {df_rtm_ham.shape} ({df_rtm_ham_raw.shape[0] - df_rtm_ham.shape[0]})\")\n",
    "\n",
    "\n",
    "df_fxt_rtm_raw = pd.read_csv(\n",
    "    '../resources/felixstowe_rotterdam/felixstowe_rotterdam.csv', quotechar=\"'\")\n",
    "df_fxt_rtm = clean.clean_up(df_fxt_rtm_raw)\n",
    "print(\n",
    "    f\"df_fxt_rtm: {df_fxt_rtm_raw.shape} to {df_fxt_rtm.shape} ({df_fxt_rtm_raw.shape[0] - df_fxt_rtm.shape[0]})\")\n",
    "\n",
    "df_combined_raw = pd.concat(\n",
    "    [df_rtm_ham_raw, df_fxt_rtm_raw], ignore_index=True)\n",
    "df_combined = pd.concat([df_rtm_ham, df_fxt_rtm], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code selects specific features from the combined DataFrame for further processing. These features are then prepared using a function from the predictor.clean module. Three time-related features are dropped from the data, then the remaining data (x) and target variable (y) are split into training and testing sets using scikit-learn's train_test_split() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from predictor.broker import ETTAgent\n",
    "\n",
    "\n",
    "def prepare_and_split(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    X, y = clean.prepare_data(df)\n",
    "    X = X.drop(\n",
    "        [\n",
    "            \"EndTime\", \"time\",\n",
    "            \"shiptype\"\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def controlled_test(\n",
    "    ett_agent: ETTAgent,\n",
    ") -> dict[str, float]:\n",
    "    ett_agent.train()\n",
    "    result = ett_agent.get_result_dict()\n",
    "    print(f\"{ett_agent.name}: {result['R2_Score']}\")\n",
    "    return result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading the data\n",
    "# ett_agents_dict: dict[str, ETTAgent] = {}\n",
    "# for file in os.listdir('./models/'):\n",
    "#     if file.endswith('.joblib'):\n",
    "#         ett_agents_dict[file.replace('.joblib', '')] = ETTAgent.load(f'./models/{file}')\n",
    "#     else:\n",
    "#         print(f'File {file} is not a joblib file')\n",
    "\n",
    "# # checking whether the data is loaded correctly\n",
    "# results = {}\n",
    "# for ett_agent_name, ett_agent in ett_agents_dict.items():\n",
    "#     result = ett_agent.get_result_dict()\n",
    "#     print(f\"{ett_agent_name}: {result['R2_Score']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've imported several machine learning methods into our code to compare results and choose the best one. These methods are:\n",
    "\n",
    "\n",
    "**Random Forest Regressor**: An ensemble learning method that fits multiple decision trees on various sub-samples of the dataset and averages the predictions.\n",
    "\n",
    "**Gradient Boosting Regressor**: Sequentially adds predictors to an ensemble, each one correcting its predecessor, to reduce both bias and variance.\n",
    "\n",
    "**AdaBoost Regressor**: An ensemble learning method that combines multiple weak regressors by assigning weights to the training data points and adjusting the weights based on the performance of each weak regressor.\n",
    "\n",
    "**Bagging Regressor**: An ensemble learning method that fits multiple instances of a base regressor on random subsets of the training data and averages their predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) Regressor: Predicts the target by finding the most similar instances in the training set and averaging their targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TripID', 'MMSI', 'ID', 'StartLatitude', 'StartLongitude',\n",
       "       'EndLatitude', 'EndLongitude', 'Latitude', 'Longitude', 'StartTime',\n",
       "       'EndTime', 'time', 'StartPort', 'EndPort', 'shiptype', 'Length',\n",
       "       'Breadth', 'Draught', 'SOG', 'COG', 'TH', 'Destination', 'Name',\n",
       "       'Callsign', 'AisSourcen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rtm_ham.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66768.78113536, 43256.99946555, 18947.16998636, ...,\n",
       "       63746.62053703, 19453.21275856, 12439.26605158])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ett_agent = ETTAgent(\n",
    "    name='test_ett_agent',\n",
    "    estimator=linear_model.LinearRegression(),\n",
    "    data=df_rtm_ham,\n",
    "    custom_feature_include_list=[\n",
    "        \"EndLatitude\", \"EndLongitude\",\n",
    "        \"Latitude\", \"Longitude\",\n",
    "        \"Length\",\n",
    "        \"SOG\"\n",
    "    ]\n",
    ")\n",
    "test_ett_agent.train()\n",
    "test_ett_agent.dump(\"test\")\n",
    "\n",
    "test_ett_agent.test()\n",
    "ETTAgent.load(\"test/test_ett_agent.joblib\").test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EndLatitude', 'EndLongitude', 'Latitude', 'Longitude', 'Length',\n",
       "       'SOG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ett_agent.X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'klll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m klll\n",
      "\u001b[1;31mNameError\u001b[0m: name 'klll' is not defined"
     ]
    }
   ],
   "source": [
    "klll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_models = {\n",
    "    'LinearRegression': linear_model.LinearRegression(),\n",
    "    'Ridge': linear_model.Ridge(),\n",
    "    'Lasso': linear_model.Lasso(),\n",
    "    'ElasticNet': linear_model.ElasticNet(),\n",
    "    'Lars': linear_model.Lars(),\n",
    "    'LassoLars': linear_model.LassoLars(),\n",
    "    'BayesianRidge': linear_model.BayesianRidge(),\n",
    "}\n",
    "\n",
    "tree_models = {\n",
    "    'DecisionTreeRegressor': tree.DecisionTreeRegressor(),\n",
    "}\n",
    "\n",
    "ensamble_models = {\n",
    "    'RandomForestRegressor': ensemble.RandomForestRegressor(n_estimators=10),\n",
    "    # 'GradientBoostingRegressor': ensemble.GradientBoostingRegressor(),\n",
    "    # 'AdaBoostRegressor': ensemble.AdaBoostRegressor(),\n",
    "    'BaggingRegressor': ensemble.BaggingRegressor(),\n",
    "}\n",
    "\n",
    "neighbors_models = {\n",
    "    'KNeighborsRegressor': neighbors.KNeighborsRegressor(),\n",
    "}\n",
    "\n",
    "# comebine the above lists into one list\n",
    "all_models = {}\n",
    "all_models.update(linear_models)\n",
    "all_models.update(tree_models)\n",
    "all_models.update(ensamble_models)\n",
    "all_models.update(neighbors_models)\n",
    "# print(all_models)\n",
    "results = {}\n",
    "ett_agents = []\n",
    "for name, estimator in all_models.items():\n",
    "    ett_agent = ETTAgent(\n",
    "        name=name,\n",
    "        estimator=estimator,\n",
    "        data=df_rtm_ham,\n",
    "        custom_feature_include_list=[\n",
    "            \"EndLatitude\", \"EndLongitude\",\n",
    "            \"Latitude\", \"Longitude\",\n",
    "            \"Length\", # \"Breadth\",\n",
    "            \"SOG\",\n",
    "        ]\n",
    "    )\n",
    "    results[name] = controlled_test(ett_agent)\n",
    "    # ett_agent.dump('./models')\n",
    "    # ett_agents.append(ett_agent)\n",
    "\n",
    "report = pd.DataFrame.from_dict(results, orient='index')\n",
    "report.sort_values(by=['R2_Score'], ascending=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models + scalars\n",
    "In the below cell, we compare the four best models with all (?) scalars\n",
    "\n",
    "\n",
    "\n",
    "What we learn is a few things.\n",
    "\n",
    "- Random Forest Regressor is the best followed by the Bagging Regressor.\n",
    "- Robust Scalar seems to be the most performant in general.\n",
    "- The Normalizer scalar increases the waiting time by a large margin\n",
    "- In general the \"scalars\", **Normalizer**, **QuantileTransformer (normal and uniform)** and **PowerTransformer** aren't that good.\n",
    "\n",
    "From now on, we will only use **RandomForestRegressor** and **BaggingRegressor** with **MinMaxScalar** and **RobustScalar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rtm_ham'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_trip_route(df: pd.DataFrame) -> str:\n",
    "    result: str = \"\"\n",
    "    start_port = df.iloc[0]['StartPort']\n",
    "    end_port = df.iloc[0]['EndPort']\n",
    "\n",
    "    if start_port == \"ROTTERDAM\" and end_port == \"HAMBURG\":\n",
    "        result = \"rtm_ham\"\n",
    "    elif start_port == \"FELIXSTOWE\" and end_port == \"ROTTERDAM\":\n",
    "        result = \"fxt_rtm\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid trip route\")\n",
    "    return result\n",
    "\n",
    "determine_trip_route(df_rtm_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor-NoScalar: 0.9672350479866193\n",
      "RandomForestRegressor-StandardScaler: 0.9674937763829506\n",
      "RandomForestRegressor-MinMaxScaler: 0.9677704490747941\n",
      "RandomForestRegressor-MaxAbsScaler: 0.9672282442464158\n",
      "RandomForestRegressor-RobustScaler: 0.9676647624129505\n",
      "BaggingRegressor-NoScalar: 0.96760328260728\n",
      "BaggingRegressor-StandardScaler: 0.9674751390321701\n",
      "BaggingRegressor-MinMaxScaler: 0.9675798191214784\n",
      "BaggingRegressor-MaxAbsScaler: 0.9677082180033267\n",
      "BaggingRegressor-RobustScaler: 0.9674625473761835\n",
      "LinearRegression-NoScalar: 0.8714616606602892\n",
      "LinearRegression-StandardScaler: 0.8714616606602896\n",
      "LinearRegression-MinMaxScaler: 0.8714616606602894\n",
      "LinearRegression-MaxAbsScaler: 0.871461660660289\n",
      "LinearRegression-RobustScaler: 0.8714616606602896\n",
      "KNeighborsRegressor-NoScalar: 0.9566785052903908\n",
      "KNeighborsRegressor-StandardScaler: 0.965343580762632\n",
      "KNeighborsRegressor-MinMaxScaler: 0.966978450152101\n",
      "KNeighborsRegressor-MaxAbsScaler: 0.9597605575601368\n",
      "KNeighborsRegressor-RobustScaler: 0.9646048561193165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2_Score</th>\n",
       "      <th>time</th>\n",
       "      <th>MAE 0</th>\n",
       "      <th>RMSE 0</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor-MinMaxScaler</th>\n",
       "      <td>0.967770</td>\n",
       "      <td>6.477368</td>\n",
       "      <td>13 minutes, 34 seconds</td>\n",
       "      <td>27 minutes, 24 seconds</td>\n",
       "      <td>[23786.4, 32652.0, 5342.457142857143, 7262.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor-MaxAbsScaler</th>\n",
       "      <td>0.967708</td>\n",
       "      <td>6.611809</td>\n",
       "      <td>13 minutes, 30 seconds</td>\n",
       "      <td>27 minutes, 26 seconds</td>\n",
       "      <td>[23880.0, 36258.0, 5151.8, 7350.0, 24609.0, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor-RobustScaler</th>\n",
       "      <td>0.967665</td>\n",
       "      <td>6.386238</td>\n",
       "      <td>13 minutes, 34 seconds</td>\n",
       "      <td>27 minutes, 27 seconds</td>\n",
       "      <td>[23747.5, 32364.0, 5480.2, 7388.4, 24204.0, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor-NoScalar</th>\n",
       "      <td>0.967603</td>\n",
       "      <td>6.288185</td>\n",
       "      <td>13 minutes, 30 seconds</td>\n",
       "      <td>27 minutes, 28 seconds</td>\n",
       "      <td>[23894.0, 27258.0, 5227.214285714285, 7086.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor-MinMaxScaler</th>\n",
       "      <td>0.967580</td>\n",
       "      <td>6.406582</td>\n",
       "      <td>13 minutes, 32 seconds</td>\n",
       "      <td>27 minutes, 29 seconds</td>\n",
       "      <td>[23902.0, 28590.0, 5078.0, 6947.0, 24270.0, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor-StandardScaler</th>\n",
       "      <td>0.967494</td>\n",
       "      <td>6.392709</td>\n",
       "      <td>13 minutes, 34 seconds</td>\n",
       "      <td>27 minutes, 31 seconds</td>\n",
       "      <td>[23713.5, 32118.0, 5324.214285714285, 7144.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor-StandardScaler</th>\n",
       "      <td>0.967475</td>\n",
       "      <td>6.331311</td>\n",
       "      <td>13 minutes, 31 seconds</td>\n",
       "      <td>27 minutes, 31 seconds</td>\n",
       "      <td>[24042.0, 27366.0, 5568.2, 6927.75, 24252.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor-RobustScaler</th>\n",
       "      <td>0.967463</td>\n",
       "      <td>6.572836</td>\n",
       "      <td>13 minutes, 32 seconds</td>\n",
       "      <td>27 minutes, 32 seconds</td>\n",
       "      <td>[23974.2, 27948.0, 5066.5, 7536.0, 24654.0, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor-NoScalar</th>\n",
       "      <td>0.967235</td>\n",
       "      <td>6.327099</td>\n",
       "      <td>13 minutes, 34 seconds</td>\n",
       "      <td>27 minutes, 38 seconds</td>\n",
       "      <td>[23605.0, 30690.0, 5260.3, 6717.5, 24460.0, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor-MaxAbsScaler</th>\n",
       "      <td>0.967228</td>\n",
       "      <td>6.429845</td>\n",
       "      <td>13 minutes, 35 seconds</td>\n",
       "      <td>27 minutes, 38 seconds</td>\n",
       "      <td>[24144.0, 29382.0, 5197.4, 7228.5, 24684.0, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor-MinMaxScaler</th>\n",
       "      <td>0.966978</td>\n",
       "      <td>0.265872</td>\n",
       "      <td>13 minutes, 55 seconds</td>\n",
       "      <td>27 minutes, 44 seconds</td>\n",
       "      <td>[23544.0, 46224.0, 5460.0, 6264.0, 25308.0, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor-StandardScaler</th>\n",
       "      <td>0.965344</td>\n",
       "      <td>0.276993</td>\n",
       "      <td>14 minutes</td>\n",
       "      <td>28 minutes, 25 seconds</td>\n",
       "      <td>[23604.0, 37104.0, 5208.0, 6876.0, 25308.0, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor-RobustScaler</th>\n",
       "      <td>0.964605</td>\n",
       "      <td>0.357993</td>\n",
       "      <td>14 minutes, 8 seconds</td>\n",
       "      <td>28 minutes, 43 seconds</td>\n",
       "      <td>[23604.0, 37320.0, 5208.0, 6864.0, 25092.0, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor-MaxAbsScaler</th>\n",
       "      <td>0.959761</td>\n",
       "      <td>0.352047</td>\n",
       "      <td>15 minutes, 46 seconds</td>\n",
       "      <td>30 minutes, 37 seconds</td>\n",
       "      <td>[23352.0, 27528.0, 5460.0, 6300.0, 24984.0, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor-NoScalar</th>\n",
       "      <td>0.956679</td>\n",
       "      <td>0.290163</td>\n",
       "      <td>16 minutes</td>\n",
       "      <td>31 minutes, 46 seconds</td>\n",
       "      <td>[23604.0, 36384.0, 5208.0, 6768.0, 24588.0, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression-RobustScaler</th>\n",
       "      <td>0.871462</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>35 minutes, 3 seconds</td>\n",
       "      <td>54 minutes, 44 seconds</td>\n",
       "      <td>[23833.802515340096, 29149.534530366866, 6544....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression-StandardScaler</th>\n",
       "      <td>0.871462</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>35 minutes, 3 seconds</td>\n",
       "      <td>54 minutes, 44 seconds</td>\n",
       "      <td>[23833.802515339907, 29149.534530367033, 6544....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression-MinMaxScaler</th>\n",
       "      <td>0.871462</td>\n",
       "      <td>0.049918</td>\n",
       "      <td>35 minutes, 3 seconds</td>\n",
       "      <td>54 minutes, 44 seconds</td>\n",
       "      <td>[23833.80251533992, 29149.534530367535, 6544.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression-NoScalar</th>\n",
       "      <td>0.871462</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>35 minutes, 3 seconds</td>\n",
       "      <td>54 minutes, 44 seconds</td>\n",
       "      <td>[23833.80251534027, 29149.534530367004, 6544.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression-MaxAbsScaler</th>\n",
       "      <td>0.871462</td>\n",
       "      <td>0.047907</td>\n",
       "      <td>35 minutes, 3 seconds</td>\n",
       "      <td>54 minutes, 44 seconds</td>\n",
       "      <td>[23833.80251534027, 29149.53453036677, 6544.93...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      R2_Score      time  \\\n",
       "RandomForestRegressor-MinMaxScaler    0.967770  6.477368   \n",
       "BaggingRegressor-MaxAbsScaler         0.967708  6.611809   \n",
       "RandomForestRegressor-RobustScaler    0.967665  6.386238   \n",
       "BaggingRegressor-NoScalar             0.967603  6.288185   \n",
       "BaggingRegressor-MinMaxScaler         0.967580  6.406582   \n",
       "RandomForestRegressor-StandardScaler  0.967494  6.392709   \n",
       "BaggingRegressor-StandardScaler       0.967475  6.331311   \n",
       "BaggingRegressor-RobustScaler         0.967463  6.572836   \n",
       "RandomForestRegressor-NoScalar        0.967235  6.327099   \n",
       "RandomForestRegressor-MaxAbsScaler    0.967228  6.429845   \n",
       "KNeighborsRegressor-MinMaxScaler      0.966978  0.265872   \n",
       "KNeighborsRegressor-StandardScaler    0.965344  0.276993   \n",
       "KNeighborsRegressor-RobustScaler      0.964605  0.357993   \n",
       "KNeighborsRegressor-MaxAbsScaler      0.959761  0.352047   \n",
       "KNeighborsRegressor-NoScalar          0.956679  0.290163   \n",
       "LinearRegression-RobustScaler         0.871462  0.082666   \n",
       "LinearRegression-StandardScaler       0.871462  0.055565   \n",
       "LinearRegression-MinMaxScaler         0.871462  0.049918   \n",
       "LinearRegression-NoScalar             0.871462  0.033935   \n",
       "LinearRegression-MaxAbsScaler         0.871462  0.047907   \n",
       "\n",
       "                                                       MAE 0  \\\n",
       "RandomForestRegressor-MinMaxScaler    13 minutes, 34 seconds   \n",
       "BaggingRegressor-MaxAbsScaler         13 minutes, 30 seconds   \n",
       "RandomForestRegressor-RobustScaler    13 minutes, 34 seconds   \n",
       "BaggingRegressor-NoScalar             13 minutes, 30 seconds   \n",
       "BaggingRegressor-MinMaxScaler         13 minutes, 32 seconds   \n",
       "RandomForestRegressor-StandardScaler  13 minutes, 34 seconds   \n",
       "BaggingRegressor-StandardScaler       13 minutes, 31 seconds   \n",
       "BaggingRegressor-RobustScaler         13 minutes, 32 seconds   \n",
       "RandomForestRegressor-NoScalar        13 minutes, 34 seconds   \n",
       "RandomForestRegressor-MaxAbsScaler    13 minutes, 35 seconds   \n",
       "KNeighborsRegressor-MinMaxScaler      13 minutes, 55 seconds   \n",
       "KNeighborsRegressor-StandardScaler                14 minutes   \n",
       "KNeighborsRegressor-RobustScaler       14 minutes, 8 seconds   \n",
       "KNeighborsRegressor-MaxAbsScaler      15 minutes, 46 seconds   \n",
       "KNeighborsRegressor-NoScalar                      16 minutes   \n",
       "LinearRegression-RobustScaler          35 minutes, 3 seconds   \n",
       "LinearRegression-StandardScaler        35 minutes, 3 seconds   \n",
       "LinearRegression-MinMaxScaler          35 minutes, 3 seconds   \n",
       "LinearRegression-NoScalar              35 minutes, 3 seconds   \n",
       "LinearRegression-MaxAbsScaler          35 minutes, 3 seconds   \n",
       "\n",
       "                                                      RMSE 0  \\\n",
       "RandomForestRegressor-MinMaxScaler    27 minutes, 24 seconds   \n",
       "BaggingRegressor-MaxAbsScaler         27 minutes, 26 seconds   \n",
       "RandomForestRegressor-RobustScaler    27 minutes, 27 seconds   \n",
       "BaggingRegressor-NoScalar             27 minutes, 28 seconds   \n",
       "BaggingRegressor-MinMaxScaler         27 minutes, 29 seconds   \n",
       "RandomForestRegressor-StandardScaler  27 minutes, 31 seconds   \n",
       "BaggingRegressor-StandardScaler       27 minutes, 31 seconds   \n",
       "BaggingRegressor-RobustScaler         27 minutes, 32 seconds   \n",
       "RandomForestRegressor-NoScalar        27 minutes, 38 seconds   \n",
       "RandomForestRegressor-MaxAbsScaler    27 minutes, 38 seconds   \n",
       "KNeighborsRegressor-MinMaxScaler      27 minutes, 44 seconds   \n",
       "KNeighborsRegressor-StandardScaler    28 minutes, 25 seconds   \n",
       "KNeighborsRegressor-RobustScaler      28 minutes, 43 seconds   \n",
       "KNeighborsRegressor-MaxAbsScaler      30 minutes, 37 seconds   \n",
       "KNeighborsRegressor-NoScalar          31 minutes, 46 seconds   \n",
       "LinearRegression-RobustScaler         54 minutes, 44 seconds   \n",
       "LinearRegression-StandardScaler       54 minutes, 44 seconds   \n",
       "LinearRegression-MinMaxScaler         54 minutes, 44 seconds   \n",
       "LinearRegression-NoScalar             54 minutes, 44 seconds   \n",
       "LinearRegression-MaxAbsScaler         54 minutes, 44 seconds   \n",
       "\n",
       "                                                                            Predictions  \n",
       "RandomForestRegressor-MinMaxScaler    [23786.4, 32652.0, 5342.457142857143, 7262.0, ...  \n",
       "BaggingRegressor-MaxAbsScaler         [23880.0, 36258.0, 5151.8, 7350.0, 24609.0, 22...  \n",
       "RandomForestRegressor-RobustScaler    [23747.5, 32364.0, 5480.2, 7388.4, 24204.0, 23...  \n",
       "BaggingRegressor-NoScalar             [23894.0, 27258.0, 5227.214285714285, 7086.0, ...  \n",
       "BaggingRegressor-MinMaxScaler         [23902.0, 28590.0, 5078.0, 6947.0, 24270.0, 22...  \n",
       "RandomForestRegressor-StandardScaler  [23713.5, 32118.0, 5324.214285714285, 7144.5, ...  \n",
       "BaggingRegressor-StandardScaler       [24042.0, 27366.0, 5568.2, 6927.75, 24252.0, 2...  \n",
       "BaggingRegressor-RobustScaler         [23974.2, 27948.0, 5066.5, 7536.0, 24654.0, 22...  \n",
       "RandomForestRegressor-NoScalar        [23605.0, 30690.0, 5260.3, 6717.5, 24460.0, 23...  \n",
       "RandomForestRegressor-MaxAbsScaler    [24144.0, 29382.0, 5197.4, 7228.5, 24684.0, 22...  \n",
       "KNeighborsRegressor-MinMaxScaler      [23544.0, 46224.0, 5460.0, 6264.0, 25308.0, 23...  \n",
       "KNeighborsRegressor-StandardScaler    [23604.0, 37104.0, 5208.0, 6876.0, 25308.0, 23...  \n",
       "KNeighborsRegressor-RobustScaler      [23604.0, 37320.0, 5208.0, 6864.0, 25092.0, 23...  \n",
       "KNeighborsRegressor-MaxAbsScaler      [23352.0, 27528.0, 5460.0, 6300.0, 24984.0, 23...  \n",
       "KNeighborsRegressor-NoScalar          [23604.0, 36384.0, 5208.0, 6768.0, 24588.0, 23...  \n",
       "LinearRegression-RobustScaler         [23833.802515340096, 29149.534530366866, 6544....  \n",
       "LinearRegression-StandardScaler       [23833.802515339907, 29149.534530367033, 6544....  \n",
       "LinearRegression-MinMaxScaler         [23833.80251533992, 29149.534530367535, 6544.9...  \n",
       "LinearRegression-NoScalar             [23833.80251534027, 29149.534530367004, 6544.9...  \n",
       "LinearRegression-MaxAbsScaler         [23833.80251534027, 29149.53453036677, 6544.93...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalars = {\n",
    "    '': None,\n",
    "    'StandardScaler': preprocessing.StandardScaler(),\n",
    "    'MinMaxScaler': preprocessing.MinMaxScaler(),\n",
    "    'MaxAbsScaler': preprocessing.MaxAbsScaler(),\n",
    "    'RobustScaler': preprocessing.RobustScaler(),\n",
    "    # # NOTE: The scalars below are not that good.\n",
    "    # 'Normalizer': preprocessing.Normalizer(),\n",
    "    # 'QuantileTransformer-Normal': preprocessing.QuantileTransformer(output_distribution='normal'),\n",
    "    # 'QuantileTransformer-Uniform': preprocessing.QuantileTransformer(output_distribution='uniform'),\n",
    "    # 'PowerTransformer': preprocessing.PowerTransformer(),\n",
    "}\n",
    "\n",
    "ett_agets_dict = {\n",
    "    'RandomForestRegressor': ensemble.RandomForestRegressor(n_estimators=10),\n",
    "    'BaggingRegressor': ensemble.BaggingRegressor(),\n",
    "    'LinearRegression': linear_model.LinearRegression(),\n",
    "    'KNeighborsRegressor': neighbors.KNeighborsRegressor(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "ett_agents = []\n",
    "\n",
    "for model_name, model in ett_agets_dict.items():\n",
    "    for scalar_name, scalar in scalars.items():\n",
    "        ett_agent = ETTAgent(\n",
    "            name=f\"{model_name}-{scalar_name if scalar_name else 'NoScalar'}\",\n",
    "            estimator=pipeline.make_pipeline(scalar, model),\n",
    "            data=df_fxt_rtm,\n",
    "            custom_feature_include_list=[\n",
    "                \"EndLatitude\", \"EndLongitude\",\n",
    "                \"Length\",\n",
    "                \"Latitude\", \"Longitude\",\n",
    "                \"SOG\",\n",
    "            ]\n",
    "        )\n",
    "        results[ett_agent.name] = controlled_test(ett_agent)\n",
    "        ett_agent.dump(f'../predictor/models/{determine_trip_route(df_fxt_rtm)}')\n",
    "        ett_agents.append(ett_agent)\n",
    "\n",
    "report = pd.DataFrame.from_dict(results, orient='index')\n",
    "report.sort_values(by=['R2_Score'], ascending=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out meta hyperparameters for RandomForest\n",
    "Here we test out the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars = {\n",
    "    '': None,\n",
    "    'RobustScaler': preprocessing.RobustScaler(),\n",
    "    'MinMaxScaler': preprocessing.MinMaxScaler(),\n",
    "}\n",
    "\n",
    "ett_agets_dict = {\n",
    "    'RandomForestRegressor max_depth=25': ensemble.RandomForestRegressor(n_estimators=20, n_jobs=-1, max_depth=25),\n",
    "    'RandomForestRegressor max_depth=50': ensemble.RandomForestRegressor(n_estimators=20, n_jobs=-1, max_depth=50),\n",
    "    'RandomForestRegressor max_depth=75': ensemble.RandomForestRegressor(n_estimators=20, n_jobs=-1, max_depth=75),\n",
    "    'RandomForestRegressor max_depth=100': ensemble.RandomForestRegressor(n_estimators=20, n_jobs=-1, max_depth=100),\n",
    "    'BaggingRegressor': ensemble.BaggingRegressor(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "ett_agents = []\n",
    "for name, estimator in ett_agets_dict.items():\n",
    "    for scalar_name, scalar in scalars.items():\n",
    "        ett_agent = ETTAgent(\n",
    "            name=f\"{name}-{scalar_name if scalar_name else 'NoScalar'}\",\n",
    "            estimator=pipeline.make_pipeline(scalar, estimator),\n",
    "            data=df_rtm_ham,\n",
    "            custom_feature_include_list=[\n",
    "                \"EndLatitude\", \"EndLongitude\",\n",
    "                \"Length\", # \"Breadth\",\n",
    "                \"Latitude\", \"Longitude\",\n",
    "                \"SOG\",\n",
    "            ]\n",
    "        )\n",
    "        results[ett_agent.name] = controlled_test(ett_agent)\n",
    "        ett_agent.dump('./models')\n",
    "        ett_agents.append(ett_agent)\n",
    "\n",
    "report = pd.DataFrame.from_dict(results, orient='index')\n",
    "report.sort_values(by=['R2_Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ett_agents_dict: dict[str, ETTAgent] = {}\n",
    "files = os.listdir('./models/')\n",
    "for file in files:\n",
    "    if file.endswith('.joblib'):\n",
    "        print(f'Loading file {file}')\n",
    "        ett_agents_dict[file.replace('.joblib', '')] = ETTAgent.load(f'./models/{file}')\n",
    "    else:\n",
    "        print(f'File {file} is not a joblib file')\n",
    "print(ett_agents_dict)\n",
    "\n",
    "# Test all models on the test data\n",
    "results = {}\n",
    "for ett_agent_name, ett_agent in ett_agents_dict.items():\n",
    "    result = ett_agent.get_result_dict()\n",
    "    print(f\"{ett_agent_name}: {result['R2_Score']}\")\n",
    "    results[ett_agent_name] = result\n",
    "\n",
    "report = pd.DataFrame.from_dict(results, orient='index')\n",
    "report = report.sort_values(by=['R2_Score'], ascending=False)\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ett_agents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_into_distance_groups(df_rtm_ham, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def split_into_distance_groups(df: pd.DataFrame, group_size: int) -> list[pd.DataFrame]:\n",
    "    '''\n",
    "        Splits the dataframe into groups of distance_remaining_in_km\n",
    "\n",
    "        Parameters:\n",
    "        ___________\n",
    "        df: pd.DataFrame\n",
    "            The dataframe to split\n",
    "        group_size: int\n",
    "            The size of the groups\n",
    "\n",
    "        Returns:\n",
    "        ________\n",
    "        list[pd.DataFrame]\n",
    "            A list of dataframes\n",
    "    '''\n",
    "    max_distance: int = df[\"distance_remaining_in_km\"].max()\n",
    "    dfs = []\n",
    "    i = 0\n",
    "    while i < max_distance:\n",
    "        df_filtered = df[(df[\"distance_remaining_in_km\"] >= i) &\n",
    "                         (df[\"distance_remaining_in_km\"] < group_size + i)]\n",
    "        dfs.append(df_filtered)\n",
    "        i += group_size\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def test_fun(df: pd.DataFrame):\n",
    "    scalars = {\n",
    "        '': None,\n",
    "        'StandardScaler': preprocessing.StandardScaler(),\n",
    "        'MinMaxScaler': preprocessing.MinMaxScaler(),\n",
    "        'MaxAbsScaler': preprocessing.MaxAbsScaler(),\n",
    "        'RobustScaler': preprocessing.RobustScaler(),\n",
    "    }\n",
    "\n",
    "    models = {\n",
    "        'LinearRegression': linear_model.LinearRegression(),\n",
    "        'RandomForestRegressor': ensemble.RandomForestRegressor(n_estimators=70, n_jobs=-1),\n",
    "        'BaggingRegressor': ensemble.BaggingRegressor(\n",
    "            n_estimators=20, n_jobs=-1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    grps = split_into_distance_groups(df, 25)\n",
    "    drop_list = [\n",
    "        \"EndTime\", \"time\",\n",
    "        \"shiptype\",\n",
    "        # \"distance_remaining_in_km\",\n",
    "        # \"mean_size\",\n",
    "        # \"mean_dir_cos\", \"mean_dir_sin\"\n",
    "    ]\n",
    "    import math\n",
    "    for grp in grps:\n",
    "        min_distance = math.floor(grp['distance_remaining_in_km'].min())\n",
    "        max_distance = math.ceil(grp['distance_remaining_in_km'].max())\n",
    "        print(f\"Group: {min_distance} - {max_distance}\")\n",
    "        X, y = clean.prepare_data(grp)\n",
    "        X = X.drop(drop_list, axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        results = {}\n",
    "        for model_name, model in models.items():\n",
    "            for scalar_name, scalar in scalars.items():\n",
    "                ett_agent = ETTAgent(\n",
    "                    name=f\"{model_name}-{scalar_name if scalar_name else 'NoScalar'}\",\n",
    "                    estimator=pipeline.make_pipeline(scalar, model),\n",
    "                    data=df_rtm_ham,\n",
    "                )\n",
    "                results[ett_agent.name] = controlled_test(ett_agent)\n",
    "\n",
    "        report = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "        # for model_name in report.index:\n",
    "        #     plot_resutls(model_name, results)\n",
    "\n",
    "        report = report.sort_values(by=['R2_Score'], ascending=False)\n",
    "        display(report.head(n=2))\n",
    "\n",
    "\n",
    "# test_fun(df_fxt_rtm)\n",
    "test_fun(df_rtm_ham)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
